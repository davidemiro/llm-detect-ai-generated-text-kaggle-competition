{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6890527,"sourceType":"datasetVersion","datasetId":3942644},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":7246053,"sourceType":"datasetVersion","datasetId":4197568}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM generation text detection","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-13T02:57:42.228566Z","iopub.execute_input":"2023-12-13T02:57:42.229054Z","iopub.status.idle":"2023-12-13T02:57:42.305662Z","shell.execute_reply.started":"2023-12-13T02:57:42.229014Z","shell.execute_reply":"2023-12-13T02:57:42.304262Z"}}},{"cell_type":"code","source":"!pip install transformers\n!pip install tensorflow_text\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T20:45:38.564687Z","iopub.execute_input":"2024-01-02T20:45:38.565250Z","iopub.status.idle":"2024-01-02T20:46:03.767477Z","shell.execute_reply.started":"2024-01-02T20:45:38.565215Z","shell.execute_reply":"2024-01-02T20:46:03.766391Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: tensorflow_text in /opt/conda/lib/python3.10/site-packages (2.13.0)\nRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_text) (0.14.0)\nRequirement already satisfied: tensorflow<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_text) (2.13.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.9.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (16.0.6)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.24.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (68.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.16.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.0)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.15.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.34.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.41.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\ntrain_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\ntrain_prompts = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\")\ntrain_daigt = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\")\n\ntrain_essays.head()\n#train_prompts.head()\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-01-02T20:48:34.673477Z","iopub.execute_input":"2024-01-02T20:48:34.673838Z","iopub.status.idle":"2024-01-02T20:48:35.785555Z","shell.execute_reply.started":"2024-01-02T20:48:34.673805Z","shell.execute_reply":"2024-01-02T20:48:35.784638Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         id  prompt_id                                               text  \\\n0  0059830c          0  Cars. Cars have been around since they became ...   \n1  005db917          0  Transportation is a large necessity in most co...   \n2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n3  00940276          0  How often do you ride in a car? Do you drive a...   \n4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n\n   generated  \n0          0  \n1          0  \n2          0  \n3          0  \n4          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Datasets aligment","metadata":{}},{"cell_type":"code","source":"train_daigt[\"generated\"] = train_daigt[\"label\"]\ntrain_essays = train_essays.merge(train_prompts, on='prompt_id', how='inner')\n\ntrain_essays = pd.concat([train_essays,train_daigt])\n\ntrain_essays.loc[:,[\"prompt_name\",\"generated\"]].value_counts()\n\n\ntrain_essays[\"text\"] = train_essays[\"text\"].map(lambda x : x.lower())\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T20:48:42.919428Z","iopub.execute_input":"2024-01-02T20:48:42.920334Z","iopub.status.idle":"2024-01-02T20:48:43.273817Z","shell.execute_reply.started":"2024-01-02T20:48:42.920293Z","shell.execute_reply":"2024-01-02T20:48:43.272840Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## BERT","metadata":{}},{"cell_type":"code","source":"import keras\nimport keras_nlp\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split\n\nX = train_essays[\"text\"].values\ny = train_essays[\"generated\"].values\n\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Assuming your labels are 0 and 1\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n\n\npreprocessor = keras_nlp.models.BertPreprocessor.from_preset(\n    \"bert_large_en_uncased\",\n)\n\n# Pretrained classifier without preprocessing.\nclassifier = keras_nlp.models.BertClassifier.from_preset(\n    \"bert_large_en_uncased\",\n    num_classes = 2,\n    preprocessor = preprocessor,\n    \n)\n# Access backbone programmatically (e.g., to change `trainable`).\nclassifier.backbone.trainable = False\n\nclassifier.compile(\n    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n    optimizer = keras.optimizers.Adam(5e-5),\n    jit_compile = True,\n)\n\nhistory = classifier.fit(\n    x = X_train,\n    y = y_train,\n    validation_data = (X_val, y_val),\n    batch_size = 64,\n    epochs = 10,  # Set the number of epochs as required\n    class_weight = class_weights\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-02T20:50:51.764323Z","iopub.execute_input":"2024-01-02T20:50:51.764692Z","iopub.status.idle":"2024-01-02T20:52:15.368166Z","shell.execute_reply.started":"2024-01-02T20:50:51.764662Z","shell.execute_reply":"2024-01-02T20:52:15.366932Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Using TensorFlow backend\nDownloading data from https://storage.googleapis.com/keras-nlp/models/bert_large_en_uncased/v1/vocab.txt\n231508/231508 [==============================] - 0s 1us/step\nDownloading data from https://storage.googleapis.com/keras-nlp/models/bert_large_en_uncased/v1/model.h5\n1341009960/1341009960 [==============================] - 51s 0us/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 37\u001b[0m\n\u001b[1;32m     29\u001b[0m classifier\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     31\u001b[0m classifier\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     32\u001b[0m     loss \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     33\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m5e-5\u001b[39m),\n\u001b[1;32m     34\u001b[0m     jit_compile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set the number of epochs as required\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras_nlp/src/utils/pipeline_model.py:201\u001b[0m, in \u001b[0;36mPipelineModel.fit\u001b[0;34m(self, x, y, batch_size, sample_weight, validation_data, validation_split, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m         (vx, vy, vsw) \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(\n\u001b[1;32m    195\u001b[0m             validation_data\n\u001b[1;32m    196\u001b[0m         )\n\u001b[1;32m    197\u001b[0m         validation_data \u001b[38;5;241m=\u001b[39m _convert_inputs_to_dataset(\n\u001b[1;32m    198\u001b[0m             vx, vy, vsw, batch_size\n\u001b[1;32m    199\u001b[0m         )\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1317\u001b[0m, in \u001b[0;36mDataHandler._configure_dataset_and_inferred_steps\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m x\n\u001b[1;32m   1316\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter\u001b[38;5;241m.\u001b[39mget_dataset()\n\u001b[0;32m-> 1317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_weight:\n\u001b[1;32m   1318\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(_make_class_weight_map_fn(class_weight))\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_steps(steps_per_epoch, dataset)\n","\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"],"ename":"ValueError","evalue":"The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()","output_type":"error"}]},{"cell_type":"code","source":"## Evaluation and submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\nsubmission_dict = {\"id\":[],\"generated\":[]}\n\nfor _,row in test_essays.iterrows():\n    submission_dict[\"id\"].append(row[\"id\"])\n    submission_dict[\"generated\"].append(classifier.predict(row[\"text\"])[1])\n\nsubmission = pd.DataFrame.from_dict(submission_dict)\nsubmission.to_csv(\"/kaggle/working/submission.csv\")\n\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}