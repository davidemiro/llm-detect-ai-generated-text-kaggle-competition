{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6890527,"sourceType":"datasetVersion","datasetId":3942644},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":7246053,"sourceType":"datasetVersion","datasetId":4197568}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM generation text detection","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-13T02:57:42.228566Z","iopub.execute_input":"2023-12-13T02:57:42.229054Z","iopub.status.idle":"2023-12-13T02:57:42.305662Z","shell.execute_reply.started":"2023-12-13T02:57:42.229014Z","shell.execute_reply":"2023-12-13T02:57:42.304262Z"}}},{"cell_type":"code","source":"!pip install transformers\n!pip install tensorflow_text\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T10:00:15.085222Z","iopub.execute_input":"2023-12-31T10:00:15.085620Z","iopub.status.idle":"2023-12-31T10:00:39.903997Z","shell.execute_reply.started":"2023-12-31T10:00:15.085584Z","shell.execute_reply":"2023-12-31T10:00:39.902921Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\nRequirement already satisfied: tensorflow_text in /opt/conda/lib/python3.10/site-packages (2.13.0)\nRequirement already satisfied: tensorflow-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_text) (0.14.0)\nRequirement already satisfied: tensorflow<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_text) (2.13.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.9.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (16.0.6)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.24.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (68.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.16.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.0)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.15.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.34.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.41.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\ntrain_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\ntrain_prompts = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\")\ntrain_daigt = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\")\n\ntrain_essays.head()\n#train_prompts.head()\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-12-31T11:18:49.609484Z","iopub.execute_input":"2023-12-31T11:18:49.609852Z","iopub.status.idle":"2023-12-31T11:18:50.776975Z","shell.execute_reply.started":"2023-12-31T11:18:49.609815Z","shell.execute_reply":"2023-12-31T11:18:50.775688Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"         id  prompt_id                                               text  \\\n0  0059830c          0  Cars. Cars have been around since they became ...   \n1  005db917          0  Transportation is a large necessity in most co...   \n2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n3  00940276          0  How often do you ride in a car? Do you drive a...   \n4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n\n   generated  \n0          0  \n1          0  \n2          0  \n3          0  \n4          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Datasets aligment","metadata":{}},{"cell_type":"code","source":"train_daigt[\"generated\"] = train_daigt[\"label\"]\ntrain_essays = train_essays.merge(train_prompts, on='prompt_id', how='inner')\n\ntrain_essays = pd.concat([train_essays,train_daigt])\n\ntrain_essays.loc[:,[\"prompt_name\",\"generated\"]].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-31T10:01:43.065283Z","iopub.execute_input":"2023-12-31T10:01:43.066350Z","iopub.status.idle":"2023-12-31T10:01:43.126096Z","shell.execute_reply.started":"2023-12-31T10:01:43.066307Z","shell.execute_reply":"2023-12-31T10:01:43.125195Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"prompt_name                            generated\nSeeking multiple opinions              1            3624\nDistance learning                      1            3397\nDoes the electoral college work?       0            3382\nCar-free cities                        0            3373\nFacial action coding system            0            2167\nDistance learning                      0            2157\nCar-free cities                        1            2052\nDriverless cars                        0            1886\nExploring Venus                        0            1862\nSummer projects                        0            1750\nDoes the electoral college work?       1            1722\nMandatory extracurricular activities   0            1670\nCell phones at school                  0            1656\nGrades for extracurricular activities  0            1626\nThe Face on Mars                       0            1583\nSeeking multiple opinions              0            1552\nCommunity service                      0            1542\nMandatory extracurricular activities   1            1407\n\"A Cowboy Who Rode the Waves\"          0            1372\nPhones and driving                     0            1168\nSummer projects                        1             951\nFacial action coding system            1             917\nCommunity service                      1             550\n\"A Cowboy Who Rode the Waves\"          1             524\nGrades for extracurricular activities  1             490\nCell phones at school                  1             463\nPhones and driving                     1             415\nDriverless cars                        1             364\nExploring Venus                        1             314\nThe Face on Mars                       1             310\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Text preprocessing","metadata":{}},{"cell_type":"code","source":"import re\nimport spacy\n\n\n# Load the English NLP model\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef preprocess_text(text):\n    # Convert to lowercase  \n    text = text.lower()\n    \n    # Remove URLs\n    text = re.sub(r'http\\S+', '', text)\n    \n    # Remove HTML tags\n    text = re.sub(r'<.*?>', '', text)\n    \n    # Remove non-alphabetic characters\n    text = re.sub(r'[^a-zA-Z]', ' ', text)\n    \n    # Tokenization using spaCy\n    doc = nlp(text)\n    tokens = [token.text for token in doc]\n    \n    # Remove stopwords using spaCy's built-in stopword list\n    tokens = [token for token in tokens if not nlp.vocab[token].is_stop]\n    \n    # Lemmatization\n    tokens = [token.lemma_ for token in nlp(\" \".join(tokens))]\n    \n    # Join tokens back into a string\n    processed_text = ' '.join(tokens)\n    \n    return processed_text\n\n#train_essays[\"bert_input\"] = train_essays[\"text\"].map(lambda x : preprocess_text(x))","metadata":{"execution":{"iopub.status.busy":"2023-12-31T10:01:49.546771Z","iopub.execute_input":"2023-12-31T10:01:49.547159Z","iopub.status.idle":"2023-12-31T10:01:57.407696Z","shell.execute_reply.started":"2023-12-31T10:01:49.547111Z","shell.execute_reply":"2023-12-31T10:01:57.406588Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocessing and Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\nfrom keras_nlp.models import BertPreprocessor\nimport keras\n\nclass BertCustomPreprocessor(BertPreprocessor):\n    def __init__(self, sequence_length, tokenizer, preprocessing, truncate, df, **kwargs):\n        super().__init__(tokenizer, sequence_length, truncate)\n        self.preprocessing = preprocessing\n        self.df = df\n\n    def to_bert_input(self, batch):\n        batch_prep = []\n        for b in batch:\n            if self.df[\"bert_input\"][b] == \"\":\n                self.df[\"bert_input\"][b] = self.preprocessing(self.df[\"text\"][b])\n            batch_prep.append(self.df[\"bert_input\"][b])\n        return\n                \n\n    def __call__(self, x, y=None, sample_weight=None):\n        x[\"bert_input\"] = x.apply(lambda x: self.to_bert_input(x), axis=1)\n        x.bert_input = x.bert_input.astype(str)\n        return super(BertCustomPreprocessor,self).__call__(x[\"bert_input\"].tolist(), y, sample_weight)\n\nclass PreprocessCallback(keras.callbacks.Callback):\n    \n    def __init__(self, preprocessing, sequence_length, truncate):\n        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n        self.truncate = truncate\n        \n    def on_epoch_begin(self, epoch, logs=None):\n        # Check and preprocess the training data\n        X_train[\"input\"] = X_train.apply(lambda row : to_model_input(row))\n        \n    def to_model_input(row):\n        \n        if row[\"input\"] == None:\n            return self.preprocess_and_tokenize(row[\"text\"])\n        else:\n            return row[\"input\"]\n\n    def preprocess_and_tokenize(self, text):\n        import pdb;pdb.set_trace()\n        return self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            truncation=self.truncation_strategy\n        )\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T11:19:14.490692Z","iopub.execute_input":"2023-12-31T11:19:14.491072Z","iopub.status.idle":"2023-12-31T11:19:14.505986Z","shell.execute_reply.started":"2023-12-31T11:19:14.491046Z","shell.execute_reply":"2023-12-31T11:19:14.504899Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## BERT","metadata":{}},{"cell_type":"code","source":"### grid_search\n\nbatch_size = [32,64]\nlearning_rate = [1e-4,1e-5]\ntrainable_backbone = [True,False]","metadata":{"execution":{"iopub.status.busy":"2023-12-30T19:27:02.037738Z","iopub.execute_input":"2023-12-30T19:27:02.038457Z","iopub.status.idle":"2023-12-30T19:27:02.045686Z","shell.execute_reply.started":"2023-12-30T19:27:02.038414Z","shell.execute_reply":"2023-12-30T19:27:02.043778Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import keras\nimport keras_nlp\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split\n\nX = train_essays[\"text\"].values\ny = train_essays[\"generated\"].values\nimport pdb;pdb.set_trace()\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Assuming your labels are 0 and 1\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n\n\n# Pretrained classifier without preprocessing.\nclassifier = keras_nlp.models.BertClassifier.from_preset(\n    \"bert_large_en_uncased\",\n    num_classes=2,\n    preprocessor=None,\n    \n)\n# Access backbone programmatically (e.g., to change `trainable`).\nclassifier.backbone.trainable = False\n\nclassifier.compile(\n    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n    optimizer=keras.optimizers.Adam(5e-5),\n    jit_compile=True,\n)\n\nhistory = classifier.fit(\n    x=X_train,\n    y=y_train,\n    validation_data=(X_val, y_val),\n    batch_size=64,\n    epochs=10,  # Set the number of epochs as required\n    class_weight=class_weights\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T20:07:43.960317Z","iopub.execute_input":"2023-12-30T20:07:43.960692Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"--Return--\nNone\n> \u001b[0;32m/tmp/ipykernel_42/1569331090.py\u001b[0m(9)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m      7 \u001b[0;31m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_essays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8 \u001b[0;31m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_essays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generated\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m----> 9 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11 \u001b[0;31m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  type(X)\n"},{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  X.shape\n"},{"name":"stdout","text":"(46246,)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  X[0]\n"},{"name":"stdout","text":"'Cars. Cars have been around since they became famous in the 1900s, when Henry Ford created and built the first ModelT. Cars have played a major role in our every day lives since then. But now, people are starting to question if limiting car usage would be a good thing. To me, limiting the use of cars might be a good thing to do.\\n\\nIn like matter of this, article, \"In German Suburb, Life Goes On Without Cars,\" by Elizabeth Rosenthal states, how automobiles are the linchpin of suburbs, where middle class families from either Shanghai or Chicago tend to make their homes. Experts say how this is a huge impediment to current efforts to reduce greenhouse gas emissions from tailpipe. Passenger cars are responsible for 12 percent of greenhouse gas emissions in Europe...and up to 50 percent in some carintensive areas in the United States. Cars are the main reason for the greenhouse gas emissions because of a lot of people driving them around all the time getting where they need to go. Article, \"Paris bans driving due to smog,\" by Robert Duffer says, how Paris, after days of nearrecord pollution, enforced a partial driving ban to clear the air of the global city. It also says, how on Monday, motorist with evennumbered license plates were ordered to leave their cars at home or be fined a 22euro fine 31. The same order would be applied to oddnumbered plates the following day. Cars are the reason for polluting entire cities like Paris. This shows how bad cars can be because, of all the pollution that they can cause to an entire city.\\n\\nLikewise, in the article, \"Carfree day is spinning into a big hit in Bogota,\" by Andrew Selsky says, how programs that\\'s set to spread to other countries, millions of Columbians hiked, biked, skated, or took the bus to work during a carfree day, leaving streets of this capital city eerily devoid of traffic jams. It was the third straight year cars have been banned with only buses and taxis permitted for the Day Without Cars in the capital city of 7 million. People like the idea of having carfree days because, it allows them to lesson the pollution that cars put out of their exhaust from people driving all the time. The article also tells how parks and sports centers have bustled throughout the city uneven, pitted sidewalks have been replaced by broad, smooth sidewalks rushhour restrictions have dramatically cut traffic and new restaurants and upscale shopping districts have cropped up. Having no cars has been good for the country of Columbia because, it has aloud them to repair things that have needed repairs for a long time, traffic jams have gone down, and restaurants and shopping districts have popped up, all due to the fact of having less cars around.\\n\\nIn conclusion, the use of less cars and having carfree days, have had a big impact on the environment of cities because, it is cutting down the air pollution that the cars have majorly polluted, it has aloud countries like Columbia to repair sidewalks, and cut down traffic jams. Limiting the use of cars would be a good thing for America. So we should limit the use of cars by maybe riding a bike, or maybe walking somewhere that isn\\'t that far from you and doesn\\'t need the use of a car to get you there. To me, limiting the use of cars might be a good thing to do.'\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  y.shape\n"},{"name":"stdout","text":"(46246,)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  y[0[\n"},{"name":"stdout","text":"*** SyntaxError: '[' was never closed\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  y[0]\n"},{"name":"stdout","text":"0\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  y[1]\n"},{"name":"stdout","text":"0\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  np.where(y == 1)\n"},{"name":"stdout","text":"(array([  648,  1039,  1057, ..., 46243, 46244, 46245]),)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  y[648]\n"},{"name":"stdout","text":"1\n--KeyboardInterrupt--\n\nKeyboardInterrupt: Interrupted by user\n","output_type":"stream"}]},{"cell_type":"code","source":"## Evaluation and submission","metadata":{"execution":{"iopub.status.busy":"2023-12-30T19:34:18.948108Z","iopub.status.idle":"2023-12-30T19:34:18.948571Z","shell.execute_reply.started":"2023-12-30T19:34:18.948317Z","shell.execute_reply":"2023-12-30T19:34:18.948340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\nsubmission_dict = {\"id\":[],\"generated\":[]}\n\nfor _,row in test_essays.iterrows():\n    submission_dict[\"id\"].append(row[\"id\"])\n    submission_dict[\"generated\"].append(classifier.predict(row[\"text\"])[1])\n\nsubmission = pd.DataFrame.from_dict(submission_dict)\nsubmission.to_csv(\"/kaggle/working/submission.csv\")\n\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T19:34:18.951698Z","iopub.status.idle":"2023-12-30T19:34:18.952000Z","shell.execute_reply.started":"2023-12-30T19:34:18.951850Z","shell.execute_reply":"2023-12-30T19:34:18.951866Z"},"trusted":true},"execution_count":null,"outputs":[]}]}