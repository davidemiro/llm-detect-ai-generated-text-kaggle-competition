{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":6901341,"sourceType":"datasetVersion","datasetId":3960967},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":7294503,"sourceType":"datasetVersion","datasetId":4210720},{"sourceId":5916,"sourceType":"modelInstanceVersion","modelInstanceId":4689},{"sourceId":6068,"sourceType":"modelInstanceVersion","modelInstanceId":4689}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LLM generation text detection ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nimport keras_nlp\nimport re\nimport spacy\nimport time\nimport string\n\n\ntrain_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\ntrain_prompts = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\")\ntrain_daigt_v2 = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\")\ntrain_daigt_external = pd.read_csv(\"/kaggle/input/daigt-external-train-dataset/train_external_drcat_02.csv\")\ntrain_daigt_v3_01 = pd.read_csv(\"/kaggle/input/daigt-v3-train-dataset/train_v3_drcat_01.csv\")\ntrain_daigt_v3_02 = pd.read_csv(\"/kaggle/input/daigt-v3-train-dataset/train_v3_drcat_02.csv\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T12:32:31.114855Z","iopub.execute_input":"2024-01-22T12:32:31.115712Z","iopub.status.idle":"2024-01-22T12:33:19.080408Z","shell.execute_reply.started":"2024-01-22T12:32:31.115668Z","shell.execute_reply":"2024-01-22T12:33:19.079539Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using TensorFlow backend\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_42/2416471652.py:14: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n  train_daigt_external = pd.read_csv(\"/kaggle/input/daigt-external-train-dataset/train_external_drcat_02.csv\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train_daigt_external.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-22T01:25:07.451874Z","iopub.execute_input":"2024-01-22T01:25:07.452183Z","iopub.status.idle":"2024-01-22T01:25:07.459031Z","shell.execute_reply.started":"2024-01-22T01:25:07.452157Z","shell.execute_reply":"2024-01-22T01:25:07.458037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Datasets ","metadata":{}},{"cell_type":"code","source":"train_daigt_v2[\"generated\"] = train_daigt_v2[\"label\"].astype(int)\ntrain_daigt_external = train_daigt_external.dropna(subset=[\"label\"])\ntrain_daigt_external[\"generated\"] = train_daigt_external[\"label\"].astype(int)\n\ntrain_daigt_v3_01[\"generated\"] = train_daigt_v3_01[\"label\"].astype(int)\ntrain_daigt_v3_02[\"generated\"] = train_daigt_v3_02[\"label\"].astype(int)\n\ntrain_essays = train_essays.merge(train_prompts, on='prompt_id', how='inner')\n\ntrain_essays = pd.concat([train_essays,train_daigt_v2,train_daigt_external,train_daigt_v3_01,train_daigt_v3_02])\n\ntrain_essays = train_essays.drop_duplicates(subset=['text'])\ntrain_essays.reset_index(drop=True, inplace=True)\n#train_essays.loc[:,[\"prompt_name\",\"generated\"]].value_counts()\n\ntrain_essays = train_essays.loc[:,[\"text\",\"generated\"]]\n\n\n\n\ntrain_essays = train_essays[train_essays['text'].apply(lambda x: isinstance(x, str))]\n\ntrain_essays = train_essays.sample(frac = 1)\n\n\n\n\ntrain_essays = train_essays[train_essays['text'].apply(lambda x: isinstance(x, str))]\n\ntrain_essays = train_essays.sample(frac = 1)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T12:05:06.974054Z","iopub.execute_input":"2024-01-22T12:05:06.975075Z","iopub.status.idle":"2024-01-22T12:05:07.491393Z","shell.execute_reply.started":"2024-01-22T12:05:06.975033Z","shell.execute_reply":"2024-01-22T12:05:07.490274Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"from multiprocessing import Pool\n\n# Load the English NLP model\nnlp = spacy.load(\"en_core_web_sm\")\n\ntable = str.maketrans(\"\", \"\", string.punctuation)\ntable[10] = None #\\n\ntable[92] = None #\\\n\n\n#to lower\nfor code in range(26):\n    table[code + 65] = code +97\n\n\n\n\ndef preprocess_text(text):\n    \n    #characters level preprocessing\n    #remove \\n and \\, remove puntuactions, to lower case\n    text = text.translate(table)\n    \n    # Tokenization using spaCy\n    doc = nlp(text)\n    \n    # Remove stopwords and lemmization using spaCy's built-in stopword list\n    tokens = [token.lemma_ for token in doc if not nlp.vocab[token.text].is_stop]\n    \n    return \" \".join(tokens)\n\n\n\n\nstart_time = time.time()\n# Number of parallel processes (adjust according to your CPU cores)\nnum_processes = 4\n\n# Split the DataFrame into chunks\nchunks = np.array_split(train_essays.loc[:,\"text\"], num_processes)\n\n# Function to apply to each chunk in parallel\ndef parallel_map(chunk):\n    return chunk.map(lambda x : preprocess_text(x))\n\n\n# Initialize a Pool for parallel processing\nwith Pool(num_processes) as pool:\n    # Use map function to apply the parallel_map function to each chunk\n    results = pool.map(parallel_map, chunks)\n\n# Concatenate the results back into a single DataFrame\ntrain_essays[\"text\"] = pd.concat(results, axis=0)\n\n\n#train_essays.loc[:,\"text\"] = train_essays.loc[:,\"text\"].map(lambda x : preprocess_text(x))\n# Convert back to pandas DataFrame (if needed)\nend_time = time.time()\n\nprint(end_time - start_time)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T12:05:16.230895Z","iopub.execute_input":"2024-01-22T12:05:16.231791Z","iopub.status.idle":"2024-01-22T12:09:58.541231Z","shell.execute_reply.started":"2024-01-22T12:05:16.231755Z","shell.execute_reply":"2024-01-22T12:09:58.539919Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"},{"name":"stdout","text":"281.1146728992462\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## DistilBERT","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n\nprint(train_essays.columns)\n\nX = train_essays[\"text\"].values\ny = train_essays[\"generated\"].values\n\n\n\n\n\n#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Assuming your labels are 0 and 1\nclass_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n\n\nbatch_size = 32\ndropout_prob = 0.2\n\n\n# Preprocessor\npreprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(\"distil_bert_base_en_uncased\",\n                                                            sequence_length=512,\n                                                                  truncate=\"waterfall\")\n\n\n# Pretrained classifier.\nclassifier = keras_nlp.models.DistilBertClassifier.from_preset(\n    \"distil_bert_base_en_uncased\",\n    preprocessor,\n    dropout = dropout_prob,\n    num_classes=1\n)\n\n\n\n\n# Access backbone programmatically (e.g., to change `trainable`).\nclassifier.backbone.trainable = True\n\nfor layer in classifier.backbone.layers[:7]:\n    layer.trainable = False\n    \nclassifier.summary()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-22T12:34:17.640173Z","iopub.execute_input":"2024-01-22T12:34:17.640574Z","iopub.status.idle":"2024-01-22T12:34:26.827812Z","shell.execute_reply.started":"2024-01-22T12:34:17.640542Z","shell.execute_reply":"2024-01-22T12:34:26.826817Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Attaching 'tokenizer.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/1' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/1' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.txt' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/1' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/1' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/1' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/1' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/1' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.txt' from model 'keras/distil_bert/keras/distil_bert_base_en_uncased/1' to your Kaggle notebook...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"distil_bert_preprocessor_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"distil_bert_preprocessor_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ distil_bert_tokenizer (\u001b[38;5;33mDistilBertTokenizer\u001b[0m)        │                                              \u001b[38;5;34m30,522\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ distil_bert_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistilBertTokenizer</span>)        │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">30,522</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"distil_bert_classifier_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"distil_bert_classifier_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                           │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ distil_bert_backbone (\u001b[38;5;33mDistilBertBackbone\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                      │      \u001b[38;5;34m66,362,880\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ tf.__operators__.getitem_1 (\u001b[38;5;33mSlicingOpLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                            │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ pooled_dense (\u001b[38;5;33mDense\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                            │         \u001b[38;5;34m590,592\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ classifier_dropout (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)                            │               \u001b[38;5;34m0\u001b[0m │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ logits (\u001b[38;5;33mDense\u001b[0m)                                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                              │             \u001b[38;5;34m769\u001b[0m │\n└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                  </span>┃<span style=\"font-weight: bold\"> Output Shape                           </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ distil_bert_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DistilBertBackbone</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">66,362,880</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ tf.__operators__.getitem_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SlicingOpLambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ pooled_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ classifier_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)                            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├───────────────────────────────────────────────┼────────────────────────────────────────┼─────────────────┤\n│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">769</span> │\n└───────────────────────────────────────────────┴────────────────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,954,241\u001b[0m (255.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,954,241</span> (255.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,942,849\u001b[0m (110.41 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,942,849</span> (110.41 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m38,011,392\u001b[0m (145.00 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,011,392</span> (145.00 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(monitor='auc',\n                                         min_delta = 0.01,\n                                         patience = 1,\n                                         mode = \"max\",\n                                         restore_best_weights = True)\n\nclassifier.compile(\n            loss=keras.losses.BinaryCrossentropy(from_logits=False),\n            optimizer=keras.optimizers.AdamW(1e-6),\n            metrics = [keras.metrics.AUC()],\n            jit_compile=True,\n        )\n\nclassifier.fit(\n    x = X,\n    y = y,\n    batch_size = batch_size,\n    epochs = 4,\n    callbacks = [early_stopping],\n    class_weight = {0:class_weights[0],1:class_weights[1]}\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T12:12:30.480748Z","iopub.execute_input":"2024-01-22T12:12:30.481698Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/4\n313/313 [==============================] - 327s 930ms/step - loss: 0.6682 - auc: 0.6796\nEpoch 2/4\n313/313 [==============================] - 268s 857ms/step - loss: 0.2856 - auc: 0.9576\nEpoch 3/4\n313/313 [==============================] - 268s 857ms/step - loss: 0.2281 - auc: 0.9751\nEpoch 4/4\n 24/313 [=>............................] - ETA: 4:07 - loss: 0.2368 - auc: 0.9766","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation and submission","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"test_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\ntest_essays.loc[:,\"text\"] = test_essays.loc[:,\"text\"].map(lambda x : preprocess_text(x))\nsubmission_dict  = pd.DataFrame()\nsubmission_dict[\"id\"] = test_essays[\"id\"]\nsubmission_dict[\"generated\"] = classifier.predict(test_essays[\"text\"])[:,0]\n\n\nsubmission = pd.DataFrame.from_dict(submission_dict)\nsubmission.to_csv(\"/kaggle/working/submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}